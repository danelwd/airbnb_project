## 19

import pandas as pd
from sklearn.model_selection import train_test_split

# ×©×œ×‘ 1: ×§×¨×™××ª ×”× ×ª×•× ×™×
df = pd.read_csv("C:/Users/Danel Wittner/Desktop/ai/airbnb_new/notebooks/data/my_processed_listings.csv")  # type: ignore # ×˜×•×¢×Ÿ ××ª ×”× ×ª×•× ×™× ××§×•×‘×¥ CSV ×‘×ª×™×§×™×™×ª data

# ×©×œ×‘ 2: ×”×¤×¨×“×ª ××©×ª× ×™ ×§×œ×˜ (features) ×××©×ª× ×” ×”××˜×¨×” (price)
# ×›×œ ×”×¢××•×“×•×ª ×—×•×¥ ×-"price" ×”×Ÿ ××©×ª× ×™ ×§×œ×˜
X = df.drop("price", axis=1)
# ×¢××•×“×ª "price" ×”×™× ××©×ª× ×” ×”××˜×¨×”
y = df["price"]

# ×©×œ×‘ 3: ×—×œ×•×§×ª ×”× ×ª×•× ×™× ×œ×¡×˜ ××™××•×Ÿ (Train) ×•×¡×˜ ×‘×“×™×§×” (Test)
# 80% ××”× ×ª×•× ×™× ×œ××™××•×Ÿ, 20% ×œ×‘×“×™×§×”
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
# random_state ×§×•×‘×¢ ××ª ×”"×’×¨×¢×™×Ÿ" ×œ×”×’×¨×œ×”, ×›×“×™ ×©×”×ª×•×¦××” ×ª×”×™×” ×©×—×–×•×¨×™×ª

#  ××•×©×œ×‘ 4: ×©××™×¨×ª ×”×¡×˜×™× ×œ×§×‘×¦×™× (×× × ×¨×¦×” ×œ×”×¢×¨×™×š ××ª ×”××•×“×œ ×‘×¢×ª×™×“ ×¢×œ×ª× × ×ª×•× ×™×)
X_train.to_csv("X_train.csv", index=False)
X_test.to_csv("X_test.csv", index=False)
y_train.to_csv("y_train.csv", index=False)
y_test.to_csv("y_test.csv", index=False)

# ×”×¡×‘×¨×™×:
# - ×”×¤×¨×“× ×• ×‘×™×Ÿ ××©×ª× ×™ ×§×œ×˜ ×œ××©×ª× ×” ××˜×¨×” ×›×“×™ ×©×”××•×“×œ ×™×œ××“ ×œ×—×–×•×ª ××ª ×”××—×™×¨ ×¢×œ ×¡××š ×××¤×™×™× ×™ ×”× ×›×¡ ×‘×œ×‘×“.
# - ×—×™×œ×§× ×• ××ª ×”× ×ª×•× ×™× ×œ×¡×˜ ××™××•×Ÿ ×•×¡×˜ ×‘×“×™×§×” ×›×“×™ ×©× ×•×›×œ ×œ×”×¢×¨×™×š ××ª ×”××•×“×œ ×¢×œ × ×ª×•× ×™× ×©×”×•× ×œ× ×¨××” ×‘×ª×”×œ×™×š ×”××™××•×Ÿ.
# - ×©××¨× ×• ××ª ×”×¡×˜×™× ×œ×§×‘×¦×™× ×›×“×™ ×©× ×•×›×œ ×œ×—×–×•×¨ ××œ×™×”× ×‘×¢×ª×™×“ ×•×œ×”×©×•×•×ª ×‘×™×¦×•×¢×™ ××•×“×œ×™× ×©×•× ×™× ×¢×œ ××•×ª× × ×ª×•× ×™×.

print("âœ… Data split completed. Shapes:")
print("X_train:", X_train.shape, "X_test:", X_test.shape)



## 22

import pandas as pd
from catboost import CatBoostRegressor # type: ignore
from sklearn.metrics import mean_absolute_error, r2_score
import joblib


# Step 1: Load preprocessed data
X_train = pd.read_csv("X_train.csv")
y_train = pd.read_csv("y_train.csv")
X_test = pd.read_csv("X_test.csv")
y_test = pd.read_csv("y_test.csv")

# Step 1.5: Identify and handle categorical features
# Get categorical columns (object/string columns)
categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()
print(f"ğŸ“Š Categorical features found: {categorical_features}")

# Convert categorical features to category type for CatBoost
for col in categorical_features:
    X_train[col] = X_train[col].astype('category')
    X_test[col] = X_test[col].astype('category')

# Get the indices of categorical features
cat_features_indices = [X_train.columns.get_loc(col) for col in categorical_features]
print(f"ğŸ“Š Categorical feature indices: {cat_features_indices}")

# Step 2: Initialize the CatBoost model
model = CatBoostRegressor(
    iterations=100,
    learning_rate=0.1,
    depth=6,
    random_state=42,
    verbose=0  # ×©×™× 100 ×× ××ª×” ×¨×•×¦×” ×œ×¨××•×ª ×¢×“×›×•× ×™× ×›×œ 100 ××™×˜×¨×¦×™×•×ª
)

# Step 3: Train the model with categorical features
model.fit(X_train, y_train.values.ravel(), cat_features=cat_features_indices)

# Step 4: Evaluate on the test set
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"ğŸ“Š Evaluation Results:")
print(f"MAE (Mean Absolute Error): {mae:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# Step 5: Save model to .pkl file
#joblib.dump(model, "models/price_predictor_catboost.pkl")
#print("ğŸ’¾ Model saved to models/price_predictor_catboost.pkl")

# Step 6: Interpretation of results
if mae < 30:
    print("âœ… The model is highly accurate with very small price errors.")
elif mae < 80:
    print("âš ï¸ The model is decent, but may over- or under-predict prices by $50â€“100 on average.")
else:
    print("âŒ The model is inaccurate â€” some predictions may be way off.")

if r2 > 0.8:
    print("âœ… The model explains most of the price variability â€” strong performance.")
elif r2 > 0.5:
    print("âš ï¸ Moderate performance â€” some important factors might be missing.")
else:
    print("âŒ The model performs poorly â€” features may be insufficient.")


## 22
